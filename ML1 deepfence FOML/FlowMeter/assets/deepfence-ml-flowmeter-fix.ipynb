{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.13.2)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"/Users/madhang/Downloads/ML1 deepfence/venv/bin/python\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "import warnings\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Function to load and clean data\n",
    "def load_and_clean_data(folder, fname_benign, fname_malicious):\n",
    "    benign_data = pd.read_csv(folder + fname_benign)\n",
    "    malicious_data = pd.read_csv(folder + fname_malicious)\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    benign_data.dropna(inplace=True)\n",
    "    malicious_data.dropna(inplace=True)\n",
    "\n",
    "    benign_data[\"Type\"] = \"Benign\"\n",
    "    malicious_data[\"Type\"] = \"Malicious\"\n",
    "\n",
    "    combined_data = pd.concat([malicious_data, benign_data])\n",
    "    combined_data = combined_data.sample(frac=1)  # Random shuffle\n",
    "\n",
    "    return combined_data\n",
    "\n",
    "# Function to add throughput columns\n",
    "def add_throughput_columns(df):\n",
    "    colsPerTime = [\n",
    "        \"flowLength\",\n",
    "        \"fwdFlowLength\",\n",
    "        \"bwdFlowLength\",\n",
    "        \"packetSizeTotal\",\n",
    "        \"fwdPacketSizeTotal\",\n",
    "        \"bwdPacketSizeTotal\",\n",
    "    ]\n",
    "\n",
    "    for feature in colsPerTime:\n",
    "        df[feature + \"PerTime\"] = df[feature] / df[\"flowDuration\"]\n",
    "        print(feature + \"PerTime\")\n",
    "\n",
    "# Function to clean the dataset\n",
    "def clean_dataset(df):\n",
    "    df.dropna(inplace=True)\n",
    "    df_X = df.iloc[:, :-1]\n",
    "    df_Y = df.iloc[:, -1]\n",
    "\n",
    "    indices_to_keep = ~df_X.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df_X[indices_to_keep].astype(np.float64).values, df_Y[indices_to_keep].values\n",
    "\n",
    "# Load and clean the data\n",
    "folder = \"../pkg/flowOutput/\"\n",
    "fname_benign = \"2017-05-02_kali-normal22_flow_stats.csv\"\n",
    "fname_malicious = \"webgoat_flow_stats.csv\"\n",
    "\n",
    "combined_data = load_and_clean_data(folder, fname_benign, fname_malicious)\n",
    "\n",
    "# Add throughput columns\n",
    "add_throughput_columns(combined_data)\n",
    "\n",
    "# Define feature columns\n",
    "feature_cols = [\n",
    "    # Your feature columns here\n",
    "]\n",
    "\n",
    "# Select feature columns in datasets\n",
    "pd_comb_features = combined_data[feature_cols]\n",
    "\n",
    "# Get feature and class arrays\n",
    "X, y = clean_dataset(pd_comb_features.copy(deep=True))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = scaler.fit_transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "# Weighted Logistic Regression\n",
    "# Define hyperparameter grid\n",
    "hyperparam_grid = {\n",
    "    # Your hyperparameters here\n",
    "}\n",
    "\n",
    "# Model fitting\n",
    "lg = LogisticRegression(random_state=13)\n",
    "grid = GridSearchCV(lg, hyperparam_grid, scoring=\"roc_auc\", cv=10, n_jobs=-1, refit=True)\n",
    "grid.fit(X_train_scale, y_train2.astype(\"int32\"))\n",
    "\n",
    "# Print best score and parameters\n",
    "print(f\"Best score: {grid.best_score_} with param: {grid.best_params_}\")\n",
    "\n",
    "# Test performance\n",
    "y_pred_wt = grid.predict(X_test_scale)\n",
    "\n",
    "# Performance metrics\n",
    "conf_mat = confusion_matrix(y_test2.astype(\"int32\"), y_pred_wt)\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test2.astype('int32'), y_pred_wt)}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test2.astype('int32'), y_pred_wt)}\")\n",
    "print(f\"Area Under Curve: {roc_auc_score(y_test2.astype('int32'), y_pred_wt)}\")\n",
    "print(f\"Recall score (Pct of true malicious detected): {100 * recall_score(y_test2.astype('int32'), y_pred_wt)}\")\n",
    "print(f\"Data reduction: {np.round(100.0 * conf_mat.T[1].sum() / conf_mat.sum(), 2)} percent\")\n",
    "print(f\"Pct malicious in data sent to console: {np.round(100.0 * conf_mat.T[1][1] / conf_mat.T[1].sum(), 2)} percent\")\n",
    "print(\"F1 score:\", f1_score(y_test2.astype(\"int32\"), y_pred_wt, average=\"weighted\"))\n",
    "\n",
    "# Save parameters\n",
    "np.savetxt(\"mean.txt\", scaler.mean_, delimiter=\",\")\n",
    "np.savetxt(\"std.txt\", scaler.scale_, delimiter=\",\")\n",
    "np.savetxt(\"weights.txt\", best_fit_model.coef_[0], delimiter=\",\")\n",
    "np.savetxt(\"intercept.txt\", best_fit_model.intercept_, delimiter=\",\")\n",
    "\n",
    "# Feature importance scores\n",
    "important_features = pd_comb_features_cp.iloc[:, :-1].columns.values[np.argsort(-1 * np.abs(best_fit_model.coef_[0])]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
